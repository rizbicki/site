---
title: "Distribuições normal, chi-quadrado e F"
author: "Rafael B. Stern"
highlight: true
date: ""
output: html_document
type: book
weight: 60
bibliography: refs.bib
---



<div id="propriedades-de-variáveis-aleatórias" class="section level1">
<h1>Propriedades de variáveis aleatórias</h1>
<p>Uma forma de descrever a incerteza em relação
a uma variável aleatória é por meio de sua
<strong>função de densidade</strong>.
Se <span class="math inline">\(X\)</span> é uma variável aleatória, geralmente
designamos a função de densidade de <span class="math inline">\(X\)</span>
por <span class="math inline">\(f_{X}(x)\)</span>.
O valor de <span class="math inline">\(f_{X}(x)\)</span> indica o quão plausível é
que a variável aleatória <span class="math inline">\(X\)</span> assuma o valor <span class="math inline">\(x\)</span>.
Por exemplo, a figura abaixo indica uma
variável aleatória contínua tal que
todos os valores entre 0 e 1 são igualmente plausíveis.
Por isso, é comum dizer que esta variável aleatória
tem densidade uniforme entre 0 e 1.</p>
<pre class="r"><code>library(tidyverse)
ggplot(data.frame(x = c(0, 1)), aes(x)) + 
stat_function(fun = dunif, colour = &quot;red&quot;, n = 100)</code></pre>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Uma propriedade importante de uma função de densidade é que
podemos obter a probabilidade de que <span class="math inline">\(X\)</span> esteja entre dois valores,
<span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span>, calculando a área debaixo da densidade.
Note que de corre desta propriedade que
a área total debaixo da densidade é <span class="math inline">\(1\)</span>.
Por exemplo, a figura abaixo ilustra como
obter <span class="math inline">\(P(0.25 &lt; X &lt; 0.5)\)</span> quando
<span class="math inline">\(X\)</span> tem densidade uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>.
Note que, neste caso, a figura abaixo da curva é
um retângulo de base <span class="math inline">\(0.25\)</span> e altura <span class="math inline">\(1\)</span> e, portanto,
de área <span class="math inline">\(0.25\)</span>. Assim, obtemos que
<span class="math inline">\(P(0.25 &lt; X &lt; 0.5) = 0.25\)</span>.
Também, a área total debaixo da densidade é
dada por um quadrado de lado <span class="math inline">\(1\)</span>, isto é, <span class="math inline">\(1\)</span>.
Portanto, como esperávamos, <span class="math inline">\(P(0 &lt; X &lt; 1) = 1\)</span>.</p>
<pre class="r"><code>ggplot(data.frame(x = c(0, 1)), aes(x)) + 
stat_function(fun = dunif, colour = &quot;red&quot;, n = 100) +
stat_function(fun = dunif, xlim = c(0.25, 0.5), geom = &quot;area&quot;, alpha = 0.5) </code></pre>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>De forma geral, a área debaixo de uma curva é
dada por uma integral.
Neste curso não usaremos esta relação,
mas é útil saber que,
se <span class="math inline">\(X\)</span> é uma variável contínua, então
obtemos que
<span class="math display">\[P(x_1 \leq X \leq x_2) = \int_{x_1}^{x_2} f_{X}(x)dx\]</span></p>
<p>Também note que a área entre <span class="math inline">\(x_1\)</span> e <span class="math inline">\(x_2\)</span>
pode ser descrita como a área à esquerda de
<span class="math inline">\(x_2\)</span> subtraída da área à esquerda de <span class="math inline">\(x_1\)</span>.
Assim, se <span class="math inline">\(X\)</span> é uma variável contínua,
também vale a seguinte relação
<span class="math display">\[P(x_1 \leq X \leq x_2) = P(X \leq x_2) - P(X \leq x_1)\]</span></p>
<p>A função de densidade descreve toda
a incerteza sobre uma variável aleatória.
Contudo, pode ser difícil descrever e
analisar uma função. Assim,
é comum que certos aspectos de
uma variável aleatória sejam resumidos
em números. A seguir, estudamos
algumas destas medidas resumo.</p>
<ul>
<li><p><strong>Esperança</strong> (média populacional):
A esperança de uma varíavel aleatória, <span class="math inline">\(X\)</span> é
denotada por <span class="math inline">\(E[X]\)</span> e descreve
uma medida de centralidade desta.
Se imaginarmos que, para cada possível valor, <span class="math inline">\(x\)</span>,
existe um peso de <span class="math inline">\(f_{X}(x)\)</span> na posição <span class="math inline">\(x\)</span>, então
<span class="math inline">\(E[X]\)</span> descreve o centro de massa desse sistema.
Também, a média amostral e a esperança resumem
a mesma característica.
Enquanto que a primeira descreve a centralidade para
uma variável em um banco de dados,
uma variável aleatória já observada,
a segunda descreve a centralidade para uma variável aleatória,
isto é, descreve a incerteza sobre
uma observação antes que esta ocorra.
De forma técnica, a esperança de
uma variável aleatória contínua é
calculada da seguinte forma:
<span class="math display">\[E[X] = \int_{-\infty}^{\infty}{x f_{X}(x)dx}\]</span></p></li>
<li><p><strong>Variância</strong> (populacional):
A variância de uma variável aleatória, <span class="math inline">\(X\)</span>, é
denotada por <span class="math inline">\(V[X]\)</span> e indica um resumo da
variabilidade desta.
Assim como a variância amostral descreve
a variabilidade de uma variável em um banco de dados (já observado),
a variância populacional descreve
a variabilidade de uma variável aleatória (ainda não observada).
De forma técnica, a variância de
uma variável aleatória contínua é
calculada da seguinte forma:
<span class="math display">\[V[X] = \int_{-\infty}^{\infty}{(x-E[X])^2 f_{X}(x)}dx\]</span>
Semelhantemente ao caso da variância amostral,
a variância populacional não é medida na
mesma escala da variável aleatória que ela representa.
Para obter esta escala, é comum tomar a
raiz quadrada da variância populacional.
Esta medida é chamada de <strong>desvio padrão</strong> (populacional).
Também é comum designarmos a variância de <span class="math inline">\(X\)</span> por
<span class="math inline">\(\sigma^2_X\)</span>. Esta notação é conveniente pois permite
designarmos o desvio padrão de <span class="math inline">\(X\)</span> por <span class="math inline">\(\sigma_X\)</span>.</p></li>
</ul>
<p>A seguir, estudaremos
algumas funções de densidade
essenciais para este curso.</p>
</div>
<div id="distribuição-normal" class="section level1">
<h1>Distribuição normal</h1>
<p>Uma das distribuições mais usadas é a Normal.
Formalmente, dizemos que <span class="math inline">\(X\)</span> tem
distribuição normal com
média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2\)</span> se
<span class="math inline">\(X\)</span> pode assumir qualquer número real e
sua densidade, <span class="math inline">\(f_{X}(x)\)</span>, tem a forma
<span class="math display">\[
f_{X}(x) =
\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
\]</span>
Como diremos muitas vezes neste curso que
“<span class="math inline">\(X\)</span> tem distribuição Normal com média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2\)</span>”,
abreviaremos esta expressão por <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>.
Se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, então obtem-se que
<span class="math inline">\(E[X] = \mu\)</span> e <span class="math inline">\(Var[X] = \sigma^2\)</span>.
A figura abaixo exibe a densidade da <span class="math inline">\(N(0,1)\)</span>,
também conhecida por “normal padrão”.</p>
<pre class="r"><code>ggplot(data.frame(x = c(-3, 3)), aes(x)) + 
stat_function(fun = dnorm, colour=&quot;red&quot;, n = 100) </code></pre>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Note que a densidade tem um formato de sino com
simetria ao redor do <span class="math inline">\(0\)</span>.
Decorre que a normal padrão tem média <span class="math inline">\(0\)</span>.
A densidade de uma normal com média <span class="math inline">\(\mu\)</span> e
variância <span class="math inline">\(1\)</span> terá o mesmo formato,
só que transladado por <span class="math inline">\(\mu\)</span>.
Este fato é ilustrado na figura a seguir,
em que as curvas azul e verdem indicam,
respectivamente, as densidades
da <span class="math inline">\(N(-1,1)\)</span> e da <span class="math inline">\(N(1,1)\)</span>.</p>
<pre class="r"><code>ggplot(data.frame(x = c(-4,4)), aes(x)) + 
stat_function(fun = dnorm, colour = &quot;red&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, mean = -1), 
              colour = &quot;blue&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, mean = 1), 
              colour = &quot;green&quot;, n = 100) +
ylab(&quot;densidade&quot;)</code></pre>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Semelhantemente, a figura abaixo apresenta
nas curvas verde, vermelha e azul, respectivamente,
as distribuições <span class="math inline">\(N(0, 0.25)\)</span>, <span class="math inline">\(N(0, 1)\)</span> e <span class="math inline">\(N(0, 4)\)</span>.
Note que a variância, <span class="math inline">\(\sigma^2\)</span>,
altera a escala da densidade da normal.
Quanto menor o valor de <span class="math inline">\(\sigma^2\)</span>,
mais a densidade está concentrada ao redor da média.</p>
<pre class="r"><code>ggplot(data.frame(x = c(-6,6)), aes(x)) + 
stat_function(fun = dnorm, colour = &quot;red&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, sd = 2), 
              colour = &quot;blue&quot;, n = 100) +
stat_function(fun = function(x) dnorm(x, sd = 0.5), 
              colour = &quot;green&quot;, n = 100) +
ylab(&quot;densidade&quot;)</code></pre>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Uma relação útil é que aproximadamente 95% da
densidade de uma <span class="math inline">\(N(\mu,\sigma^2)\)</span> está
concentrada entre <span class="math inline">\(\mu-2\sigma\)</span> e <span class="math inline">\(\mu+2\sigma\)</span>.
Na figura acima, temos que <span class="math inline">\(\mu=0\)</span>.
Assim, aproximadamente 95% da área das curvas
verde, vermelha e azul está concentrada,
respectivamente, em <span class="math inline">\([-1,1]\)</span>, <span class="math inline">\([-2,2]\)</span> e <span class="math inline">\([-4,4]\)</span>.
De forma mais formal,
se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span> e
<span class="math inline">\(\approx\)</span> significa aproximadamente, então
<span class="math display">\[
P(\mu-2\sigma \leq X \leq \mu+2\sigma)
\approx 0.95
\]</span></p>
<p>Se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>,
não é possível descrever <span class="math inline">\(P(X \leq x)\)</span>
de forma analítica. Contudo,
é possível obter uma aproximação analítica
para esta quantidade no <strong>R</strong> usando a função <em>pnorm</em>.
Por exemplo, o código abaixo calcula
<span class="math inline">\(P(X \leq 4)\)</span> para uma <span class="math inline">\(N(2,9)\)</span>.</p>
<pre class="r"><code>pnorm(4, mean = 2, sd = 3)</code></pre>
<pre><code>## [1] 0.7475075</code></pre>
<p>Também a probabilidade de que
uma <span class="math inline">\(N(2,9)\)</span> esteja entre <span class="math inline">\(1\)</span> e <span class="math inline">\(4\)</span>
é obtida da seguinte forma:</p>
<pre class="r"><code>pnorm(4, mean = 2, sd = 3) - pnorm(1, mean = 2, sd = 3)</code></pre>
<pre><code>## [1] 0.3780661</code></pre>
<p>É possível transformar qualquer distribuição normal
em uma normal padrão por meio de transformações lineares.
Especificamente, se <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, então
<span class="math inline">\(\frac{X-\mu}{\sigma} \sim N(0,1)\)</span>. Por isso,
podemos imaginar que obtemos uma <span class="math inline">\(N(\mu,\sigma^2)\)</span>,
ao multiplicar uma normal padrão por <span class="math inline">\(\sigma\)</span> e
somar <span class="math inline">\(\mu\)</span> ao resultado.
O processo de calcular <span class="math inline">\(\frac{X-\mu}{\sigma}\)</span> é
frequentemente chamado de padronização.</p>
<div id="teorema-central-do-limite" class="section level2">
<h2>Teorema Central do Limite</h2>
<p>O Teorema Central do Limite é
um dos resultados mais importantes em Estatística e
também uma das razões pelas quais
a distribuição é tão importante neste curso.
De forma suscinta, ele dita que, se
<span class="math inline">\(X_1, \ldots, X_n\)</span> são
variáveis aleatórias independentes que
tem a mesma distribuição e tais que
<span class="math inline">\(E[X_i] = \mu\)</span> e <span class="math inline">\(V[X_i] = \sigma^2\)</span>, então
a média amostral é aproximadamente normal.
Mais especificamente,
<span class="math display">\[\bar{X} \approx N\left(\mu,\frac{\sigma^2}{n}\right)\]</span>
Note que esta aproximação vale
não importa qual seja
a distribuição de cada observação.
Assim, com pouquíssimas suposições é
possível aproximar a distribuição
da média amostral pela normal.
Se padronizarmos a média amostral,
obtemos a versão mais usual do
Teorema do Limite Central:
<span class="math display">\[\frac{\bar{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} \approx N(0,1)\]</span>
A figura a seguir é um histograma de
observações obtidas tomando a média de
<span class="math inline">\(100\)</span> variáveis aleatórias uniformes entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>.
Note que cada uniforme tem média <span class="math inline">\(0.5\)</span> e as
médias amostrais estão dispersas em torno deste valor.
Também, a distribuição uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span> tem
variância <span class="math inline">\(\frac{1}{12}\)</span>. Assim,
o Teorema Central do Limite dita que a
média de 100 destas distribuições uniformes tem
desvio padrão <span class="math inline">\(\sqrt{\frac{1}{12 \cdot 100}}\)</span>.
Isto é, neste caso <span class="math inline">\(\bar{X} \approx N(0.5, 0.03)\)</span>.
De fato, observamos na figura que
a maior parte das observações estão dispersas
a menos de dois desvios padrões, <span class="math inline">\(0.06\)</span>,
da média populacional, <span class="math inline">\(0.5\)</span>.</p>
<pre class="r"><code>medias = rep(NA, 1000)
for(ii in 1:1000) 
{
  medias[ii] = mean(runif(100, 0, 1))
}
ggplot(aes(x = medias), data = data.frame(medias)) +
geom_histogram(aes(y = ..density..)) +
geom_density(colour=&quot;red&quot;)</code></pre>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="distribuição-chi-quadrado" class="section level1">
<h1>Distribuição chi-quadrado</h1>
<ul>
<li><p>Se <span class="math inline">\(X\)</span> tem distribuição chi-quadrado
com <span class="math inline">\(n\)</span> graus de liberdade, escrevemos
<span class="math inline">\(X \sim \chi^2_n\)</span>. Neste caso,
<span class="math display">\[f_{X}(x) = \frac{x^{0.5n-1}\exp(-0.5x)}{2^{0.5n}\Gamma(0.5n)},\]</span>
<span class="math inline">\(E[X]=n\)</span> e <span class="math inline">\(V[X]=2n\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X \sim N(0,1)\)</span>, então
<span class="math inline">\(X^2 \sim \chi^2_1\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis independentes e
cada qual tem distribuição <span class="math inline">\(\chi^2_1\)</span>, então
<span class="math inline">\(\sum_{i=1}^n X_i \sim \chi^2_n\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis independentes e
tais que <span class="math inline">\(X_{i} \sim N(\mu, \sigma^2)\)</span>, então
<span class="math inline">\(\frac{\sum_{i1=}^{n}(X_i-\bar{X})^2}{\sigma^2} \sim \chi^2_{n-1}\)</span>,
ou seja, <span class="math inline">\(\frac{S^2}{\sigma^2} \sim \chi^2_{n-1}\)</span>.</p></li>
<li><p>No <strong>R</strong>, podemos obter
a densidade e <span class="math inline">\(P(X \leq x)\)</span> para
a chi-quadrado por meio dos comandos
<em>dchisq</em> e <em>pchisq</em>.</p></li>
</ul>
</div>
<div id="distribuio-t-de-student" class="section level1">
<h1>Distribui??o T de Student</h1>
<ul>
<li><p>Designamos a distribui??o <span class="math inline">\(T\)</span> de Student com
<span class="math inline">\(n\)</span> graus de liberdade por <span class="math inline">\(T_{n}\)</span>.</p></li>
<li><p>Se <span class="math inline">\(Z \sim N(0,1)\)</span> e <span class="math inline">\(S^2 \sim \chi^2_n\)</span> s?o
vari?veis independentes, ent?o
<span class="math inline">\(\frac{Z}{\sqrt{\frac{S^2}{n}}} \sim T_{n}\)</span>.</p></li>
<li><p>No <strong>R</strong>, podemos obter
a densidade e <span class="math inline">\(P(X \leq x)\)</span> para
a T de Student por meio dos comandos
<em>dt</em> e <em>pt</em>.</p></li>
</ul>
</div>
<div id="distribuição-f-de-snedcor" class="section level1">
<h1>Distribuição F de Snedcor</h1>
<ul>
<li><p>Se <span class="math inline">\(X\)</span> tem distribuição <span class="math inline">\(F\)</span> com parâmetros
<span class="math inline">\(d_1\)</span> e <span class="math inline">\(d_2\)</span>, então escrevemos
<span class="math inline">\(X \sim F_{d_1,d_2}\)</span>.</p></li>
<li><p><span class="math inline">\(X_1 \sim \chi^2_{d_1}\)</span>, <span class="math inline">\(X_2 \sim \chi^2_{d_2}\)</span> e
<span class="math inline">\(X_1\)</span> e <span class="math inline">\(X_2\)</span> são independentes, então</p></li>
</ul>
<p><span class="math display">\[
\frac{\frac{X_1}{d_1}}{\frac{X_2}{d_2}}
\sim F_{d_1,d_2}
\]</span></p>
<ul>
<li>No <strong>R</strong>, podemos obter
a densidade e <span class="math inline">\(P(X \leq x)\)</span> para
a distribuição F por meio dos comandos
<em>df</em> e <em>pf</em>.</li>
</ul>
</div>
<div id="exercícios" class="section level1">
<h1>Exercícios</h1>
<ol style="list-style-type: decimal">
<li><p>Se <span class="math inline">\(X\)</span> tem densidade entre uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span> e
<span class="math inline">\(0 \leq x_1, x_2 \leq 1\)</span>, calcule <span class="math inline">\(P(x_1 \leq X \leq x_2)\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X\)</span> tem densidade uniforme entre <span class="math inline">\(1\)</span> e <span class="math inline">\(3\)</span>,
qual é o valor da densidade de <span class="math inline">\(X\)</span> neste intervalo?</p></li>
<li><p>Calcule a esperança e a variância de uma variável aleatória
com distribuição uniforme entre <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>.</p></li>
<li><p>Ache um intervalo tal que uma <span class="math inline">\(N(4,9)\)</span> e
steja dentro deste com probabilidade aproximadamente <span class="math inline">\(95\%\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X \sim N(4,9)\)</span>, utilize o <strong>R</strong> para
calcular <span class="math inline">\(P(-1 \leq X \leq 1)\)</span>.</p></li>
<li><p>Se <span class="math inline">\(X \sim N(10, 100)\)</span>, indique
uma transformação linear de <span class="math inline">\(X\)</span> que tem
distribuição normal padrão.</p></li>
<li><p>Se <span class="math inline">\(X_1, \ldots, X_n\)</span> são variáveis independentes
de mesma distribuição e tais que
<span class="math inline">\(E[X_i] = 9\)</span> e <span class="math inline">\(V[X_i] = 16\)</span>, indique valores para
<span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> tal que
<span class="math inline">\(P(a \leq \bar{X} \leq b) \approx 95\%\)</span>.</p></li>
<li><p>Um pesquisador utilizou uma mesma medida resumo
em diversas variáveis de seu banco de dados.
Para visualizar estas medidas, construiu
um histograma delas.
Este histograma se encontra abaixo.
Com base no histograma, argumente se
a medida resumo poderia ou não ser a média amostral.</p></li>
</ol>
<p><img src="/courses/intro_stat/06_distribuicoes_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="referências" class="section level1">
<h1>Referências</h1>
</div>
