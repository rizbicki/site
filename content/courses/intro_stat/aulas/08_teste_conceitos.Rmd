---
title: "Conceitos de testes de hipótese"
author: "Rafael B. Stern"
highlight: true
date: ""
output: html_document
type: book
weight: 80
bibliography: refs.bib
---

# Testes de hipótese

É comum que queiramos saber o quanto
uma amostra corrobora uma hipótese científica.
Neste caso, podemos aplicar um teste de hipótese,
isto é, um procedimento que decidirá se
a hipótese é ou não rejeitada diante da amostra obtida.

Por exemplo, considere que $X_{1}, \ldots, X_{n}$ são
observações independentes realizadas com uma régua ao
medir um determinado objeto. Suponha que 
$X_{i} \sim N(\mu, \sigma_0^2)$, onde $\sigma_0^2$ é
conhecido e indica precisão das medidas feitas com a régua.
Uma pessoa poderia estar interessada na hipótese 
de que o objeto tem $15$ cm. Formalmente, 
chamamos esta hipótese de **hipótese nula** e
a representamos por $H_0: \mu = 15$.
Gostaríamos de saber se é possível 
rejeitar $H_0$ com base nos dados.

## Tipos de erro

Existem $4$ possíveis resultados que
podem decorrer de um teste de hipótese.
Note que o teste de hipótese pode rejeitar ou
não rejeitar a hipótese nula e, também,
esta hipótese pode ser verdadeira ou falsa.
Assim, existem $4$ combinações de resultados possíveis:

- (Acerto) A hipótese nula é verdadeira e não é rejeitada.
- (Acerto) A hipótese nula é falsa e é rejeitada.
- (Erro tipo I) A hipótese nula é verdadeira e é rejeitada.
- (Erro tipo II) A hipótese nula é falsa e não é rejeitada.

Estas combinações podem ser representadas na seguinte tabela:

```{r echo = FALSE, message = FALSE, warning = FALSE}
erros = data.frame(V1 = c("Rejeita H", "Não rejeita H"),
                   V2 = c("Erro tipo I", "Acerto"),
                   V3 = c("Acerto", "Erro tipo II"))
names(erros) = c("", "H é verdadeira", "H é falsa")
DT::datatable(erros, rownames = FALSE, options = list(dom = 'ti'))
```

Note que existe um balanço entre 
os erros tipo I e II.
Por exemplo, se quiséssemos 
que a probabilidade de cometer 
um erro tipo I fosse 0, 
então poderíamos nunca rejeitar H.
Contudo, neste caso, 
a probabilidade de cometer 
um erro tipo II seria 1.
Analogamente, se sempre rejeitarmos H,
então as probabilidades de erro tipo I e II
serão, respectivamente, 1 e 0.
Na prática, rejeitamos $H_0$ quando 
os dados oferecem evidência contrária a este hipótese.
Assim, buscamos que as probabilidades de cometer
um erro tipo I ou um erro tipo II sejam baixas.

Uma outra observação importante é que,
em geral, não sabemos se cometemos um erro em um teste de hipótese.
Para saber se $H_0$ é verdadeiro ou não,
seria necessária observar a população.
Como apenas somos capazes de observar a amostra,
não somos capazes de determinar se $H_0$ é verdadeiro ou não.
Assim, não sabemos se o resultado do teste de hipótese
foi um acerto ou um erro.

Apesar da limitação acima, podemos controlar 
as probabilidades de erro tipo I e II de um teste.
Isto é, podemos desenvolver testes que,
antes de observar o banco de dados, tenham
uma baixa probabilidade de cometer um erro.

Convecionou-se que a hipótese nula deve
ser escolhida de tal forma que 
o erro tipo I seja mais grave que o erro tipo II.
Por exemplo, é mais grave concluir que 
um rio não está poluído quando ele está poluído
do que concluir que ele está poluído quando de fato não está.
Assim, neste caso, tomaríamos a hipótese nula como
aquela de que o rio está poluído, pois assim o
erro tipo I seria o de rejeitar que o rio está poluído 
quando ele de fato está.

Como o erro tipo I é o mais grave,
construímos testes de hipótese que diretamente
controlam a probabilidade de erro tipo I.
Formalmente, determinaremos testes de hipótese tais que
o erro tipo I seja menor que um valor pré-determinado, $\alpha$.
É comum que $\alpha$ seja chamado de 
**nível de significância** do teste.

### Exemplo: normal com variância conhecida

Considere que $X_{1},\ldots,X_{n}$ são 
observações independentes e tais que 
$X_{i} \sim N(\mu,\sigma_0^2)$, onde 
$\sigma_0^2$ é conhecido. Por exemplo,
$X_i$ pode ser o peso da $i$-ésima vaca
alimentada com uma determinada ração.
Deseja-se provar que o peso médio de
vacas alimentadas com esta ração é maior do que
$\mu_0 kg$, ou seja, a hipótese nula é
$H_0: \mu_0 \leq 500$.

Para capturar o quanta a evidência 
os dados trazem contra $H_0$, podemos
calcular o quanto a média amostral supera
o valor de $\mu_0$, isto é, 
$\bar{X}-\mu_0$. Gostaríamos de rejeitar
a hipótese nula quando $\bar{X}$ é muito maior que $\mu_0$,
isto é, $\bar{X}-\mu_0 > c$, onde $c$ é 
escolhido de forma a controlar o erro tipo I.
A seguir, veremos como realizar este controle.

O erro tipo I é a probabilidade de rejeitar
a hipótese nula quando ela é verdadeira.
Isto é, para obter o erro tipo I, 
queremos calcular $P(\bar{X} - \mu_0 > c)$ sob $H_0$.
Especificamente, gostaríamos que 
$P(\bar{X} - \mu_0 > c) \leq \alpha$ sob $H_0$.
Para realizar esta desigualdade, note que
decorre das propriedades da distribuição normal que, 
sob o valor extremo o extremo da hipótese nula ($\mu = \mu_0$),
temos que $\bar{X}-\mu_0 \sim N\left(0,\frac{\sigma_0^2}{n}\right)$.
Assim, utilizando a padronização da distribuição normal, obtemos que
se $\mu = 500$,
$$
 Z := \frac{\bar{X}-\mu_0}{\sqrt{\frac{\sigma_0^2}{n}}} \sim N(0, 1)
$$
Portanto,
$$
\begin{align*}
 P(\bar{X}-\mu_0 > c)
 &= P\left(\frac{\bar{X}-\mu_0}{\sqrt{\frac{\sigma_0^2}{n}}} > \frac{\sqrt{n}c}{\sigma_0}\right) \\
 &= P\left(Z > \frac{\sqrt{n}c}{\sigma_0}\right) \\
 &= 1 - P\left(Z \leq \frac{\sqrt{n}c}{\sigma_0}\right) \\
 &= 1 - \text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right)
\end{align*}
$$
Para controlar o erro tipo $I$,
desejamos que sob $H_0$,
$P(\bar{X}-\mu_0 > c) = \alpha$.
Utilizamos as equações acima, obtemos
$$
\begin{align*}
\alpha &= 1 - \text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right) \\
1- \alpha &= \text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right) \\
\text{qnorm}(1-\alpha) 
&=  \text{qnorm}\left(\text{pnorm}\left(\frac{\sqrt{n}c}{\sigma_0}\right)\right) \\
\text{qnorm}(1-\alpha) 
&= \frac{\sqrt{n}c}{\sigma_0} \\
\frac{\text{qnorm}(1-\alpha)\sigma_0}{\sqrt{n}} &= c
\end{align*}
$$
Assim, para controlar o erro tipo I em $\alpha$,
rejeitamos a a hipótese nula $H_0:\mu \leq \mu_0$ quando
$$\bar{X}-\mu_0 > \frac{\text{qnorm}(1-\alpha)\sigma_0}{\sqrt{n}}.$$

Por exemplo, considere que observamos $9$ vacas
alimentadas com a ração de interesse.
Sabemos que o desvio padrão nos pesos destas vacas é de $50 kg$
e, portanto, o peso de cada vaca é $X_i \sim N(\mu, 50)$.
O peso média destas foi de $530$.
Se desejamos testar a hipótese $H_0: \mu \leq 500$ a
um nível de $\alpha = 5\%$, podemos
realizar os cálculos no **R** da seguinte forma:
```{r}
mu0 = 500
n = 9
sigma0 = 50
media = 530
alpha = 0.05
qnorm(1-alpha)
c = qnorm(1-alpha) * sigma0 / sqrt(n)
c
media - mu0 > c
```
Como a média amostral supera $c$ a
um nível de $0.05$, rejeitamos a hipótese nula.
Note que, se exercemos um maior controle sobre
o erro tipo I, então não rejeitaremos
a hipótese nula. Por exemplo,
se tomássemos $\alpha = 0.01$,
então o teste de hipótese seria mais conservador e
não rejeitaríamos a hipótese nula.
```{r}
alpha = 0.01
qnorm(1-alpha)
c = qnorm(1-alpha) * sigma0 / sqrt(n)
c
media - mu0  > c
```

## p-valor

Na amostra estudada no exemplo anterior, 
verificamos que se fixássemos $\alpha = 0.05$,
então o teste rejeitaria a hipótese nula.
Por outro lado, se fixássemos $\alpha = 0.01$,
o teste não rejeitaria a hipótese nula.
Isto ocorre pois quanto menor o valor de $\alpha$,
mais o teste fica conservador em rejeitar $H_0$.
Decorre deste comportamento que,
enquanto que para valores "grandes" de $\alpha$, 
o teste rejeitará $H_0$, 
para valores "pequenos" de $\alpha$
o teste não rejeitará $H_0$.

Um valor de interesse é o menor $\alpha$
tal que o teste rejeita $H_0$ para a amostra observada.
Este $\alpha^*$ é comumente chamado de **p-valor**.
Este valor pode ser muito útil
para compartilhar resultados.
Note que, para a amostra observada,
se um pesquisador fixar um $\alpha > \alpha^*$,
então ele rejeitará $H_0$. Por outro lado,
se ele fixar $\alpha < \alpha^*$, 
então não rejeitará $H_0$. Assim,
somente comparando o p-valor com o $\alpha$ fixado,
é possível saber o resultado do teste.
Portanto, mesmo pesquisadores fixando
níveis de significância diferentes podem
saber o resultado do teste de hipótese apenas
observando o p-valor.

### p-valor na normal com variância conhecida

No exemplo do teste de hipótese para
a média da normal com variância conhecida, 
lembre que $H_0: \mu \leq \mu_0$ é 
rejeitado para todos os valores
de $\alpha$ tais que:

$$\bar{X}-\mu_0 > \frac{\text{qnorm}(1-\alpha)\sigma_0}{\sqrt{n}}$$
Portanto, o menor valor de $\alpha$ tal que $H_0$
é rejeitado, $\alpha^*$ é tal que
$$\bar{X}-\mu_0 = \frac{\text{qnorm}(1-\alpha^*)\sigma_0}{\sqrt{n}}$$
Com algumas manipulações aritméticas podemos determinar
o valor de $\alpha^*$, isto é, o p-valor:
$$
\begin{align*}
 \bar{X}-\mu_0 
 &= \frac{\text{qnorm}(1-\alpha^*)\sigma_0}{\sqrt{n}} \\
 \frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0} 
 &= \text{qnorm}(1-\alpha^*) \\
 \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
 &= \text{pnorm}(\text{qnorm}(1-\alpha^*)) \\
 \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
 &= 1 - \alpha^* \\
 1 - \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
 &= \alpha^*
\end{align*}
$$
Portanto, o p-valor neste caso é
o $\alpha^*$ tal que
$$
\alpha^* = 1 - \text{pnorm}\left(\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma_0}\right)
$$

# Exercícios

1. Descreva em suas próprias palavras: teste de hipótese,
erro tipo I, erro tipo II, nível de significância e p-valor.

2. Um cientista mede um objeto $9$ vezes com um paquímetro e
observa os valores em mm de: 
1.2, 1.4, 1.7, 1.3, 1.5, 1.1, 1.8, 1.4, 1.1.
Se as medições com o paquímetro tem desvio padrão de 0.2 mm,
o pesquisador consegue rejeitar a hipótese de que
o comprimento do objeto é menor do que $1.3 mm$?
Qual o p-valor para esta hipótese na amostra observada?

3. Considere o caso da normal com variância conhecida.
Ou seja, cada observação é tal que $X_{i} \sim N(\mu,\sigma_0^2)$.
Considere que desejamos testar $H_0: \mu \geq \mu_0$.
Neste caso, faria sentido calcular como evidência contra $H_0$
o quanto $\bar{X}$ é menor que $\mu_0$?
Se sim, rejeitaríamos $H_0$ quando $\bar{X}-\mu_0 < c$.
Utilizando passos análogos ao da seção da normal com variância conhecida,
o valor de $c$ tal que 
a probabilidade de erro tipo I é controlada por $\alpha$.
Determine o p-valor deste teste.

4. Considere novamente o caso da normal com variância conhecida,
ou seja, cada observação é tal que $X_{i} \sim N(\mu,\sigma_0^2)$.
A medida $|\bar{X}-\mu_0|$ captura evidência contra $H_0: \mu = \mu_0$?
Se desejamos rejeitar $H_0$ quando $|\bar{X}-\mu_0| > c$,
determine o valor de $c$ que controla o erro tipo I em $\alpha$.
Determine o p-valor deste teste.
