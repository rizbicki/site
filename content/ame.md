+++
#title = "Aprendizado de máquina: uma abordagem estatística"

date = 2020-07-28T00:00:00
draft = false

# [header]
# caption = ""
+++

<a href="../AME.pdf"><img src="../img/ame.png" alt="Book cover"   width="500px" style="float: center" border="3"/></a>
[**Aqui**](../AME.pdf) você pode baixar o livro
[Aprendizado de máquina: uma abordagem estatística](../AME.pdf), escrito por mim e pelo [Tiago Mendonça](https://www.tiagoms.com/) (ISBN 978-65-00-02410-4). A capa do livro foi feita pelos incríveis [Leonardo M. Borges](http://aquitemcaqui.com/) e [Kaori Nagata](http://www.kaorinagata.net/).

Caso queira **imprimir** o livro, 
utilize a versão 
[deste link](../AME_impressao.pdf), que possui sinalização de onde ele deve ser cortado. Sugerimos utilizar uma resolução de ao menos 500dpi.

**Citação**: Izbicki, R. e Santos, T. M. dos. *Aprendizado de máquina: uma abordagem estatística*. 1ᵃ edição. 2020. 272 páginas. ISBN: 978-65-00-02410-4.
Para a entrada em **bibtex**, [clique aqui](../citacao.bib).

## Vídeos (em desenvolvimento)

**Playlist:**

  <iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PLMZwWwAgHhmAB8-qg5HWkdB5VDr8ROeyj" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  
**Vídeos de cada capítulo:**  

- Capítulos 1 e 2
  * [Introdução](https://youtu.be/DayjLIje9to)
  * [Elementos de um problema de predição e regressão linear](https://www.youtube.com/watch?v=q2wb4tvEwpw)
  * [Overfitting](https://www.youtube.com/watch?v=QfpW4ZEiGLg)
  * [Seleção de modelos](https://youtu.be/_UaAxnzkRkA)
  * [Mais sobre data-splitting](https://youtu.be/J6J2eQWIYYI)
  * Mais sobre o risco
- Capítulo 3
  * [Lasso e seleção de variáveis](https://youtu.be/NP9mVewUVSw)
  * [Mais sobre penalização](https://www.youtube.com/watch?v=CVwVTJ3JW7c&t=1315s)
- Capítulo 4
  * [KNN, Nadaraya-Watson, Séries Ortogonais](https://youtu.be/p7tQ_cqfLBk)
  * [Árvores, Bagging e Florestas Aleatórias](https://youtu.be/80hT0_8LTGU) 
  * [Redes Neurais e Deep Learning](https://youtu.be/b73pxvFvTV0)
  * [RKHS, SVR e KRR](https://www.youtube.com/watch?v=vhXfUj0Wy3k) 
  * [Truque do Kernel](https://youtu.be/97b3vLMBcuc)
  * Teoria
- Capítulo 5
  * Maldição da dimensionalidade
- Capítulo 6
  * [Interpretabilidade/ExplainableML](https://youtu.be/12OkqR9FdA8)
  * [Inferência conformal](https://youtu.be/UIr8H2A2x0I)
  * [Estimação de densidades condicionais](https://www.youtube.com/watch?v=zROykZaxx3s)
- Capítulos 7 e 8
  * [Risco, regressão logística e classificação via regressão](https://youtu.be/8Gz7Bz_Cs5E)
  * [Seleção de modelos, outras medidas de desempenho e desbalanceamento](https://youtu.be/hIrJAG9hp0g)
  * [Outros classificadores plugin: Bayes ingênuo e análise discriminante](https://youtu.be/LUtkIamL6sw)
  * SVM
  * [KNN, árvores, florestas e redes neurais](https://youtu.be/1UQ6jhH10Iw)
  * Boosting
- Capítulo 9
  * [Assimetria na função de perda e dados desbalanceados](https://youtu.be/hIrJAG9hp0g)
  * Dataset shift e viés de seleção
  * Combinando classificadores
  * Teoria VC
- Capítulo 10
  * [PCA, KPCA e projeções aleatórias](https://youtu.be/X3qpViqVs6I)
  * Autoencoders
- Capítulo 11
  * [K-medias, clustering espectral e agrupamento hierárquico](https://youtu.be/1PFlutsdjGM)
- Capítulo 12
  * [Regras de associação](https://youtu.be/S1Jey3_SmfU)
- Capítulo 13
  * Sistemas de recomendação
- Apêndice
  * [Manipulando textos e imagens](https://youtu.be/hS8yMYS36ko)
  
  
## Bancos de dados

Estes são os bancos de dados usados no livro:

- [Amazon Fine Food reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews)
- [Hour](../dados/hour.csv)
- [Indicadores SSP](../dados/indicadores_ssp.csv)
- [Prostate](../dados/prostate.data)
- [World Development Indicators](../dados/worldDevelopmentIndicators.csv)
- [Spam](../dados/spam.txt)

